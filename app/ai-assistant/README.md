# Hedera Playground Backend

Backend API de WebSocket construido con TypeScript, Fastify y OpenAI para el asistente Hedera Playground.

## ğŸš€ CaracterÃ­sticas

- **Fastify**: Framework web rÃ¡pido y eficiente
- **WebSocket**: ComunicaciÃ³n en tiempo real con `@fastify/websocket`
- **OpenAI Integration**: Streaming de respuestas con GPT-4
- **TypeScript**: Tipado estÃ¡tico completo
- **ValidaciÃ³n**: Esquemas Zod para mensajes WebSocket
- **Health Checks**: Endpoints de monitoreo
- **Auto-reconexiÃ³n**: Manejo robusto de conexiones

## ğŸ“‹ InstalaciÃ³n

```bash
# Instalar dependencias
npm install

# Configurar variables de entorno
cp env.example .env
```

### Variables de Entorno

```env
OPENAI_API_KEY=your_openai_api_key_here
PORT=3001
NODE_ENV=development
```

## ğŸ› ï¸ Scripts

```bash
# Desarrollo con hot reload
npm run dev

# Compilar TypeScript
npm run build

# Ejecutar versiÃ³n compilada
npm start

# Tests (por implementar)
npm test
```

## ğŸ“¡ API

### WebSocket Endpoints

#### `/ws/chat`

Endpoint principal para comunicaciÃ³n de chat en tiempo real.

**Mensajes de entrada:**

```typescript
{
  type: 'chat' | 'ping',
  content: string,
  conversationId?: string,
  messageId?: string
}
```

**Respuestas:**

```typescript
{
  type: 'chat_start' | 'chat_delta' | 'chat_complete' | 'error' | 'pong',
  content?: string,
  messageId?: string,
  conversationId?: string,
  error?: string,
  metadata?: {
    model?: string,
    finishReason?: string,
    usage?: {
      promptTokens: number,
      completionTokens: number,
      totalTokens: number
    }
  }
}
```

### HTTP Endpoints

#### `GET /health`

Estado del servidor

```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T00:00:00.000Z",
  "uptime": 123.45,
  "environment": "development"
}
```

#### `GET /api/info`

InformaciÃ³n de la API

```json
{
  "name": "Hedera Playground Backend",
  "version": "1.0.0",
  "description": "WebSocket API for Hedera Playground Assistant",
  "endpoints": {
    "websocket": "/ws/chat",
    "health": "/health",
    "stats": "/api/stats"
  }
}
```

#### `GET /api/stats`

EstadÃ­sticas de conexiones

```json
{
  "activeConnections": 2,
  "connections": [
    {
      "id": "uuid-1",
      "isAlive": true,
      "messageCount": 5
    }
  ]
}
```

## ğŸ—ï¸ Arquitectura

```
src/
â”œâ”€â”€ index.ts              # Servidor principal Fastify
â”œâ”€â”€ websocket-handler.ts  # Manejo de conexiones WebSocket
â”œâ”€â”€ openai-service.ts     # Servicio de integraciÃ³n OpenAI
â””â”€â”€ types.ts             # Definiciones de tipos TypeScript
```

### Componentes Principales

#### `WebSocketHandler`

- Maneja conexiones WebSocket
- Enrutamiento de mensajes
- Health checks (ping/pong)
- GestiÃ³n de estado de conexiones

#### `OpenAIService`

- IntegraciÃ³n con OpenAI API
- Streaming de respuestas
- Manejo de historial de conversaciones
- EspecializaciÃ³n en Hedera/Web3

#### `Types`

- Esquemas de validaciÃ³n Zod
- Interfaces TypeScript
- Tipos para mensajes y respuestas

## ğŸ”§ ConfiguraciÃ³n Avanzada

### CORS

```typescript
await fastify.register(cors, {
  origin: [
    "http://localhost:3000",
    "http://localhost:5173",
    /^http:\/\/localhost:\d+$/,
  ],
  credentials: true,
});
```

### WebSocket Options

```typescript
await fastify.register(websocket, {
  options: {
    maxPayload: 1048576, // 1MB
    verifyClient: (info) => true, // Personalizar autenticaciÃ³n
  },
});
```

### OpenAI Configuration

```typescript
const stream = await this.client.chat.completions.create({
  model: 'gpt-4o',
  messages: [...],
  stream: true,
  max_tokens: 2000,
  temperature: 0.7,
});
```

## ğŸ” Logging y Debugging

El servidor incluye logging integrado con Fastify:

```bash
# Logs de desarrollo (nivel: info)
npm run dev

# Logs de producciÃ³n (nivel: warn)
NODE_ENV=production npm start
```

## ğŸš¦ Manejo de Errores

- ValidaciÃ³n de esquemas con Zod
- Error handlers globales de Fastify
- Timeout handling para conexiones WebSocket
- ReconexiÃ³n automÃ¡tica del cliente

## ğŸ“Š Monitoreo

- Health check endpoint
- EstadÃ­sticas de conexiones activas
- MÃ©tricas de uso de tokens OpenAI
- Estado de conexiones WebSocket

## ğŸ”’ Seguridad

- ValidaciÃ³n de entrada con Zod
- CORS configurado apropiadamente
- Rate limiting (por implementar)
- AutenticaciÃ³n (por implementar)

## ğŸš€ Despliegue

### Desarrollo

```bash
npm run dev
```

### ProducciÃ³n

```bash
npm run build
npm start
```

### Docker (por implementar)

```dockerfile
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY dist ./dist
EXPOSE 3001
CMD ["npm", "start"]
```

## Helm Chart

To deploy the application using Helm, follow these steps:

1. **Create a Helm Chart**:

   - Run `helm create hedera-playground-assistant` to generate a new Helm chart.
   - Replace the contents of `hedera-playground-assistant/templates/` with the Kubernetes manifests created earlier.

2. **Update `values.yaml`**:

   - Set the Docker image and other configurations as needed.

3. **Deploy the Helm Chart**:

   - Run `helm install hedera-playground-assistant ./hedera-playground-assistant` to deploy the application.

4. **Verify Deployment**:
   - Use `kubectl get pods` and `kubectl get services` to ensure the application is running correctly.

## GCP deployment with Terraform

### Prerequisites

- Google Cloud project with billing enabled
- `gcloud` CLI authenticated and configured for your project
- `terraform` >= 1.5 installed

### What Terraform creates

- Artifact Registry repo for Docker images
- Secret Manager secret `OPENAI_API_KEY`
- Cloud Run (fully managed) service for the backend
- Service Account for Cloud Run with permissions to pull images and read the secret
- Public invoker on the Cloud Run service

### 1) Build and push the Docker image

```bash
# Set these values
PROJECT_ID="your-project-id"
REGION="us-central1"
REPO="playground-backend"
IMAGE_NAME="backend"
TAG="v1"

gcloud auth configure-docker ${REGION}-docker.pkg.dev --quiet
gcloud services enable artifactregistry.googleapis.com run.googleapis.com secretmanager.googleapis.com iam.googleapis.com --project ${PROJECT_ID}

# Create repo if it does not exist
gcloud artifacts repositories create ${REPO} \
  --repository-format=docker \
  --location=${REGION} \
  --description="Docker repo for playground backend" \
  --project ${PROJECT_ID} || true

# Build and push
docker build -t ${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:${TAG} -f ./backend/Dockerfile ./backend
docker push ${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:${TAG}
```

### 2) Upload your OpenAI key to Secret Manager

```bash
gcloud secrets create OPENAI_API_KEY --replication-policy=automatic --project ${PROJECT_ID} || true
printf "%s" "$OPENAI_API_KEY" | gcloud secrets versions add OPENAI_API_KEY --data-file=- --project ${PROJECT_ID}
```

### 3) Deploy infra with Terraform

```bash
cd ../infra/terraform

terraform init
terraform apply \
  -var="project_id=${PROJECT_ID}" \
  -var="region=${REGION}" \
  -var="repository_id=${REPO}" \
  -var="service_name=playground-backend" \
  -var="image=${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:${TAG}"
```

### 4) Verify

```bash
terraform output cloud_run_url
curl "$(terraform output -raw cloud_run_url)/api/playground/assistant/health"
```

Notes:

- The service listens on port `3001` and exposes `/api/playground/assistant/health`.
- `OPENAI_API_KEY` is injected from Secret Manager at runtime. Ensure the secret has a latest version.

## GKE deployment (Kubernetes) with Terraform

If you prefer Kubernetes over Cloud Run, use the provided Terraform to create a GKE Autopilot cluster and deploy a `Service` named `hedera-playground-assistant` that exposes the app via a LoadBalancer.

### Prerequisites

- Google Cloud project with billing enabled
- `gcloud` and `terraform` installed
- Docker image pushed to Artifact Registry (see step 1 below)

### 1) Build and push the Docker image

```bash
PROJECT_ID="playground-develop-441415"
REGION="us-central1"
REPO="playground-backend"
IMAGE_NAME="backend"
TAG="v1"

gcloud auth configure-docker ${REGION}-docker.pkg.dev --quiet
gcloud services enable artifactregistry.googleapis.com container.googleapis.com secretmanager.googleapis.com iam.googleapis.com --project ${PROJECT_ID}

gcloud artifacts repositories create ${REPO} \
  --repository-format=docker \
  --location=${REGION} \
  --description="Docker repo for playground backend" \
  --project ${PROJECT_ID} || true

docker build -t ${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:${TAG} -f ./backend/Dockerfile ./backend
docker push ${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:${TAG}
```

### 2) Deploy GKE + Kubernetes resources with Terraform

```bash
cd ../infra/terraform

# Pass your secret without echoing it on the command line
export TF_VAR_openai_api_key="${OPENAI_API_KEY}"

terraform init
terraform apply \
  -var="project_id=${PROJECT_ID}" \
  -var="region=${REGION}" \
  -var="repository_id=${REPO}" \
  -var="service_name=playground-backend" \
  -var="image=${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:${TAG}" \
  -var="enable_cloud_run=false"
```

### 3) Get access and test Service

```bash
# Fetch kubeconfig for the Autopilot cluster
gcloud container clusters get-credentials playground-backend-gke --region ${REGION} --project ${PROJECT_ID}

# Wait for the LoadBalancer external IP
kubectl get svc hedera-playground-assistant -w

# Once EXTERNAL-IP is assigned, test health
EXTERNAL_IP=$(kubectl get svc hedera-playground-assistant -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
curl "http://${EXTERNAL_IP}/api/playground/assistant/health"
```

Notes:

- The Service name is `hedera-playground-assistant` and forwards port 80 -> container `3001`.
- The Deployment label selector uses `app: playground-backend` by default; keep labels in sync if you change `service_name`.

## ğŸ“ PrÃ³ximas Mejoras

- [ ] AutenticaciÃ³n JWT
- [ ] Rate limiting
- [ ] MÃ©tricas Prometheus
- [ ] Tests unitarios
- [ ] Docker containerization
- [ ] Base de datos para persistencia
- [ ] Clustering para mÃºltiples instancias
